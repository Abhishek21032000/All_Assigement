{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f44770-b594-4cf2-a8ae-58769ed63c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Web scraping, also known as web harvesting or web data extraction, is the process of automatically gathering data from websites using software or\n",
    "\n",
    "scripts. This involves extracting information from HTML or other markup language documents, which are the standard languages used to create web pages.\n",
    "\n",
    "Web scraping is used for a variety of purposes, including:\n",
    "Market Research:\n",
    "Businesses use web scraping to gather information about their competitors, including pricing data, product information, customer reviews, and more.\n",
    "\n",
    "Content Aggregation:\n",
    "Websites and apps that aggregate content from multiple sources use web scraping to extract and display information from different websites in a\n",
    "unified format.\n",
    "\n",
    "Academic Research:\n",
    "Researchers use web scraping to collect data for studies on various topics, including social media analysis, sentiment analysis, and online behavior\n",
    "analysis.\n",
    "\n",
    "Three specific areas where web scraping is used to get data are:\n",
    "E-commerce:\n",
    "Online retailers use web scraping to gather information about their competitors' products and pricing, as well as to track changes in customer\n",
    "behavior and sentiment.\n",
    "\n",
    "Job Postings:\n",
    "Job boards and recruitment agencies use web scraping to collect and analyze data on job postings, including salary ranges, job requirements, and \n",
    "other relevant information.\n",
    "\n",
    "Real Estate:\n",
    "Real estate agencies use web scraping to gather data on properties, including their location, price, features, and other relevant details. This data \n",
    "can be used to develop insights on market trends and to identify potential investment opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5167082-e80f-42db-a854-b531306a1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "Web scraping refers to the process of extracting data from websites.\n",
    "There are several methods used for web scraping, including:\n",
    "Using a web scraping tool:\n",
    "Several web scraping tools, such as BeautifulSoup, Scrapy, and Selenium, can be used to scrape data from websites. These tools provide a simple and \n",
    "automated way to scrape data from websites.\n",
    "\n",
    "Writing custom scripts:\n",
    "Custom scripts can be written in programming languages such as Python or Ruby to scrape data from websites. This approach requires knowledge of\n",
    "programming and web scraping techniques.\n",
    "\n",
    "API scraping:\n",
    "Many websites offer APIs (Application Programming Interfaces) that can be used to extract data in a structured format. These APIs provide a more\n",
    "reliable and secure way to access data compared to web scraping.\n",
    "\n",
    "Data extraction services:\n",
    "There are several data extraction services available, such as Import.io and Parsehub, that allow users to extract data from websites without writing \n",
    "any code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22aeea4-15a4-4a1d-a3fe-425e2c506e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "Beautiful Soup is used for web scraping because it simplifies the process of parsing and navigating HTML and XML documents. With Beautiful Soup,\n",
    "developers can quickly extract the data they need from websites and use it for analysis or other purposes. It is a powerful tool for data extraction\n",
    "and provides an easy-to-use interface for web scraping\n",
    "\n",
    "Some of the key features of Beautiful Soup include:\n",
    "Parse HTML and XML: Beautiful Soup can parse HTML and XML documents, and it can handle poorly formatted HTML and XML.\n",
    "\n",
    "Navigating the document: Beautiful Soup makes it easy to navigate the document tree and access specific elements and attributes.\n",
    "\n",
    "Search and filter: Beautiful Soup provides several methods to search and filter the document based on specific attributes, tags, and text.\n",
    "\n",
    "Unicode support: Beautiful Soup fully supports Unicode and can work with non-English characters and encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c74335-4091-43c1-a4a9-7ac01b4ac027",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Why is flask used in this Web Scraping project?\n",
    "flask is a lightweight web application that is commonly used for developing web applications, REST APIs, and microservices. In a web scraping project\n",
    "we use Flask because Flask can be used to create a web application that exposes the scraped data through a REST API. This allows other applications\n",
    "or services to consume the data and use it for various purposes, such as data analysis, visualization, or machine learning. Flask can also be used\n",
    "to create a simple web interface for viewing and interacting with the scraped data also Flask is very Easy to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b40f8-9812-453a-ba80-4c6a98b29684",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "We use 2 services of AWS to deploy our project\n",
    "\n",
    "1. CodePipline\n",
    "2. Elastic Beanstalk\n",
    "CodePipeline:-\n",
    "AWS CodePipeline is a continuous delivery service that automates the process of building, testing, and deploying code changes. It provides a fully \n",
    "managed pipeline for deploying code changes to various deployment targets, including AWS Elastic Beanstalk, AWS Lambda, Amazon ECS, and more. \n",
    "CodePipeline helps automate the build, test, and deploy process, making it easier to manage and deploy applications, especially in large-scale or \n",
    "complex environments.\n",
    "\n",
    "AWS Elastic Beanstalk\n",
    "It is a fully managed service that makes it easy to deploy and scale web applications on AWS. Elastic Beanstalk provides an easy-to-use platform \n",
    "for deploying and managing web applications without having to manage the underlying infrastructure. It supports a wide range of web application\n",
    "technologies, including Java, .NET, PHP, Node.js, Python, Ruby, and more. Elastic Beanstalk provides a fully managed environment for deploying web \n",
    "applications and handles the scaling and monitoring of the infrastructure.\n",
    "\n",
    "When used together, AWS CodePipeline and AWS Elastic Beanstalk can streamline the process of deploying web applications to AWS. CodePipeline\n",
    "automates the process of building and deploying code changes, while Elastic Beanstalk provides an easy-to-use platform for managing and scaling \n",
    "web applications. By using these services together, developers can focus on building their applications and leave the deployment and scaling tasks\n",
    "to AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecfe0cb-ca92-49cf-a8bb-723731dc7ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57924e1-67cc-4b84-aba6-64315170b454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee5e047-ed85-4456-9d07-13ffc8691a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
